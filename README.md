# Transfer Learning with SR-Derived Options in Reinforcement Learning

## Overview

Implementing transfer learning with agent-space based SR eigenoptions and comparing its performance against learning from scratch using primitive actions.

## Results

Agents with transferred SR eigenoptions consistently achieved broader state coverage within the same exploration horizon, improving on scratch performance in 8 out of 10 sample runs.

## Conclusion

Incorporating agent-space SR eigenoptions as temporally abstract actions provides a significant boost to exploration efficiency, offering an initial jumpstart while allowing the agent to adapt via primitive action learning.
